{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segment Road and Sidewalk\n",
    "Tony Wang July 04 2023\n",
    "\n",
    "After semantic segmentation of road and sidewalk, we obtain the pixel level binary mask of them. Which can be used to detect human-road relationship using rule-based comparision. Since the SAM didn't provide necessary api, I write some utility func to realize it\n",
    "\n",
    "> This notebook is used for tutuorial demo, because I believe, compared to the unstable .py file, jupyter notebook would provide a vivid description and data pipeline demonstration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library & Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "# filter some annoying debug info\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import supervision as sv\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from groundingdino.util.inference import Model\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "#TODO name!\n",
    "from groundingdino.util.inference import load_model, load_image, predict, annotate\n",
    "\n",
    "# import SAM_utility # \n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# Paths to GroundingDINO and SAM checkpoints\n",
    "GROUNDING_DINO_CONFIG_PATH = \"../GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\"\n",
    "GROUNDING_DINO_CHECKPOINT_PATH = \"./weights/groundingdino_swint_ogc.pth\"\n",
    "MODEL_TYPE = \"vit_b\"\n",
    "SAM_CHECKPOINT_PATH = \"./weights/sam_vit_b_01ec64.pth\"\n",
    "\n",
    "# Predict classes and hyper-param for GroundingDINO\n",
    "BOX_TRESHOLD = 0.25\n",
    "TEXT_TRESHOLD = 0.25\n",
    "PED_TRESHOLD = 0.5\n",
    "\n",
    "NMS_THRESHOLD = 0.85\n",
    "IOU_THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "# DEBUG = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DPT_module.dpt.models import DPTDepthModel\n",
    "from DPT_module.dpt.midas_net import MidasNet_large\n",
    "from DPT_module.dpt.transforms import Resize, NormalizeImage, PrepareForNet\n",
    "import DPT_module.util.io as DPT_io\n",
    "from torchvision.transforms import Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_depth(image_path, output_path, model_path=\"DPT_module/weights/dpt_large-midas-2f21e586.pt\", model_type=\"dpt_large\", optimize=True):\n",
    "    \"\"\"\n",
    "    Predict the depth map of a single image using DPT model.\n",
    "\n",
    "    Args:\n",
    "        img (ndarray): Input image.\n",
    "        model_path (str): Path to the model weights.\n",
    "        model_type (str): Type of the DPT model to use.\n",
    "\n",
    "    Returns:\n",
    "        prediction (ndarray): The predicted depth map.\n",
    "    \"\"\"\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if DEBUG:\n",
    "        print(\"initialize\")\n",
    "        print(\"device: %s\" % device)\n",
    "    # load network\n",
    "    if model_type == \"dpt_large\":\n",
    "        model = DPTDepthModel(\n",
    "            path=model_path,\n",
    "            backbone=\"vitl16_384\",\n",
    "            non_negative=True,\n",
    "            enable_attention_hooks=False,\n",
    "        )\n",
    "        normalization = NormalizeImage(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model type. Please use 'dpt_large'.\")\n",
    "\n",
    "    net_w = net_h = 384\n",
    "\n",
    "    transform = Compose(\n",
    "        [\n",
    "            Resize(\n",
    "                net_w,\n",
    "                net_h,\n",
    "                resize_target=None,\n",
    "                keep_aspect_ratio=True,\n",
    "                ensure_multiple_of=32,\n",
    "                resize_method=\"minimal\",\n",
    "                image_interpolation_method=cv2.INTER_CUBIC,\n",
    "            ),\n",
    "            normalization,\n",
    "            PrepareForNet(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    if optimize == True and device == torch.device(\"cuda\"):\n",
    "        model = model.to(memory_format=torch.channels_last)\n",
    "        model = model.half()\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # transform input\n",
    "    img = DPT_io.read_image(image_path)\n",
    "    img_input = transform({\"image\": img})[\"image\"]\n",
    "    # print(\"img.shape is\",  img.shape)\n",
    "    # compute depth map\n",
    "    with torch.no_grad():\n",
    "        sample = torch.from_numpy(img_input).to(device).unsqueeze(0)\n",
    "\n",
    "        if optimize == True and device == torch.device(\"cuda\"):\n",
    "            sample = sample.to(memory_format=torch.channels_last)\n",
    "            sample = sample.half()\n",
    "\n",
    "        prediction = model.forward(sample)\n",
    "        prediction = (\n",
    "            torch.nn.functional.interpolate(\n",
    "                prediction.unsqueeze(1),\n",
    "                size=img.shape[:2],\n",
    "                mode=\"bicubic\",\n",
    "                align_corners=False,\n",
    "            )\n",
    "            .squeeze()\n",
    "            .cpu()\n",
    "            .numpy()\n",
    "        )\n",
    "    # DPT_io.write_depth(output_path, prediction, bits=2)\n",
    "    \n",
    "    # print(\"finished\")\n",
    "    return prediction\n",
    "\n",
    "\n",
    "prediction = 0\n",
    "\n",
    "# prediction =  predict_depth(\"input/S0710/image_0006.png\",output_path=\"DINOmasked/image_0006\")\n",
    "# obj_dict =  detect_road(\"input/S0710/.png\",output_path=\"SSS.png\" )# \"DINOmasked/video_0060/image_0005.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1]\n",
      " [0 0 1]\n",
      " [1 0 0]]\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'far'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def get_distance_category(depth_map, person_mask):\n",
    "    # Define depth categories\n",
    "    categories = ['very close', 'close', 'medium', 'far', 'very far']\n",
    "\n",
    "\n",
    "    # Find the lowest true point in mask A \n",
    "    y_coords, _ = np.nonzero(person_mask)\n",
    "    lowest_point = int(np.max(y_coords) * 0.9 )#(huamn feet point)\n",
    "    # print(y_coords, lowest_point)\n",
    "    mask_a_copy = person_mask.copy().astype(bool)\n",
    "    # Slice mask A from the lowest point to the top\n",
    "    mask_a_copy[:lowest_point, :] = False\n",
    "    obj_depths = depth_map[mask_a_copy]\n",
    "      # Handle case where no depth value is available\n",
    "    if obj_depths.size == 0:\n",
    "        return \"unknown\"\n",
    "    feet_depth = np.median(obj_depths)\n",
    "\n",
    "\n",
    "    # Compute depth range of the image\n",
    "    min_depth, max_depth = np.min(depth_map), np.max(depth_map)\n",
    "\n",
    "    # Compute boundaries for each category\n",
    "    boundaries = np.linspace(min_depth, max_depth, len(categories) + 1)\n",
    "\n",
    "    # Find which category the median depth of the object belongs to\n",
    "    for i in range(len(boundaries) - 1):\n",
    "        if boundaries[i] <= feet_depth < boundaries[i + 1]:\n",
    "            return categories[i]\n",
    "\n",
    "    return categories[-1]  # If for some reason it wasn't caught in the loop\n",
    "obj_ms = np.array([ [1,1,1] ,[0,0,1],[1,0,0]   ]  )\n",
    "print(obj_ms)\n",
    "dep_ms = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(dep_ms)\n",
    "get_distance_category(dep_ms,obj_ms)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model loading is quite long\n",
    "with some unremovable warning in gDINO, just ignore it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "# Initialize GroundingDINO model\n",
    "grounding_dino_model = Model(\n",
    "    model_config_path=GROUNDING_DINO_CONFIG_PATH, \n",
    "    model_checkpoint_path=GROUNDING_DINO_CHECKPOINT_PATH, \n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "# Initialize SAM model and predictor\n",
    "sam = sam_model_registry[MODEL_TYPE](checkpoint=SAM_CHECKPOINT_PATH)\n",
    "sam.to(device=DEVICE)\n",
    "sam_predictor = SamPredictor(sam)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data structure\n",
    "LocationInfo: pack form to help data-alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocationInfo:\n",
    "    def __init__(self, object_type, id, box, mask,confidence):\n",
    "        self.object_type = object_type  # ('sidewalk', 'road', or 'person')\n",
    "        self.id = id  # Unique ID within the type\n",
    "        self.box = box  # Bounding box in xyxy format\n",
    "        self.mask = mask  # Binary mask indicating the precise location of the object\n",
    "        self.confidence = confidence #confidence of bbox\n",
    "        self.distance = None # str,{very close,close, median, far, very far}\n",
    "        self.angle = None    # horizontal angle relative to camera\n",
    "        \n",
    "        self.direction = None # str, {left, right, forward, backward}\n",
    "        self.speed  = None   # str, {slow, fast, very fast}\n",
    "\n",
    "    def get_area(self):\n",
    "        \"\"\"\n",
    "        int: The area of the object in pixels.\n",
    "        \"\"\"\n",
    "        return np.sum(self.mask)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_mask(mask, ax, random_color=False):\n",
    "    '''Display single mask to its image'''\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:] # more robust way of extracting the spatial dimensions of the array\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    \n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "    \n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_image_file(filename):\n",
    "    IMAGE_EXT = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "    return any(filename.endswith(extension) for extension in IMAGE_EXT)\n",
    "\n",
    "def display_mask(SAM_masks,P_masks, P_boxes, DINO_boxes,  person_annotation,output_path):\n",
    "    # Create a new subplot\n",
    "    plt.figure(figsize=(16,9))\n",
    "    # image = cv2.cvtColor( cv2.imread(image_path),cv2.COLOR_BGR2RGB )\n",
    "    # Display the original image\n",
    "    plt.axis('off')\n",
    " \n",
    "    plt.imshow(person_annotation)\n",
    "    i,j,k,d = 0,0,0,0\n",
    "    for mask in SAM_masks:\n",
    "        i += 1\n",
    "        show_mask(mask, plt.gca(), random_color=True)\n",
    "    for box in DINO_boxes:\n",
    "        j += 1\n",
    "        show_box(box, plt.gca())\n",
    "    for mask in P_masks:\n",
    "        k += 1\n",
    "        show_mask(mask, plt.gca(), random_color=True)\n",
    "    for box in P_boxes:\n",
    "        d += 1\n",
    "        show_box(box,plt.gca())\n",
    "    if DEBUG:\n",
    "        print(\"number of Surface mask, Road&sidewalk, People 's mask, actural people: \",i,j,k,d)\n",
    "\n",
    "    # plt.savefig(output_path)\n",
    "    plt.close()\n",
    "    return (i, j, k, d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms_processing(detections ):\n",
    "    \"\"\"\n",
    "    Non-Maximum Suppression (NMS) on detection results to eliminate overlapping bounding boxes.\n",
    "    \n",
    "    Args:\n",
    "        detections (Detection): \n",
    "        - 'xyxy' (bounding box coordinates),\n",
    "        - 'confidence' (confidence scores), \n",
    "        - 'class_id' (class IDs).\n",
    "        \n",
    "        nms_threshold (float): The threshold for the IOU (Intersection Over Union). Bounding boxes with IOU values greater than this \n",
    "        threshold will be suppressed.\n",
    "    \n",
    "    Returns:\n",
    "        detections: The updated detections after performing NMS. \n",
    "    \"\"\"\n",
    "    nms_idx = torchvision.ops.nms(\n",
    "        torch.from_numpy(detections.xyxy), \n",
    "        torch.from_numpy(detections.confidence), \n",
    "        NMS_THRESHOLD \n",
    "    ).numpy().tolist()\n",
    "\n",
    "    detections.xyxy = detections.xyxy[nms_idx]\n",
    "    detections.confidence = detections.confidence[nms_idx]\n",
    "    detections.class_id = detections.class_id[nms_idx]\n",
    "    return detections"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Architecture:\n",
    "1. gDINO : grounding_dino_model.predict_with_classes\n",
    "\n",
    "   CLASSES_prompt= ['road', 'sidewalk']\n",
    "\n",
    "   Based on testing, this pair is most reliable (otherwise the sidewalk may messed up with road) \n",
    "\n",
    "   In this part, I use the box as Region of Interest(ROI) to further prompt SAM\n",
    "\n",
    "2. Non-maximum suppression (NMS) :\n",
    "\n",
    "   get rid of redundant and overlapping bounding boxes.\n",
    "\n",
    "   the metric is Intersection over Union(IoU)\n",
    "\n",
    "3. Prompting SAM with ROI, select mask with largest area, in this step, the road and sidewalk can be segmented with naming in pixel level accuracy.\n",
    "\n",
    "4. save the result \n",
    "\n",
    "5. label the result with label and confidence\n",
    "\n",
    "6. TODO: do image sequence experiment, analyze the behavior of person\n",
    "\n",
    "7. TODO: split cases based on JAAD info\n",
    "\n",
    "   - car is moving \n",
    "   - car is stopping\n",
    "   - time\n",
    "   - weather\n",
    "   - more...\n",
    "\n",
    "In GTX3090 environment, the algorithm runs relatively fast with GPU boosting.\n",
    "\n",
    "(Not as bad as I guessed before, much faster than all of the online demo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location utility function\n",
    "- is_overlap: a mask-level comparitor func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_overlap(mask_a: np.ndarray, mask_b: np.ndarray):\n",
    "    \"\"\"\n",
    "    Check if the bottom part of mask_a overlaps with mask_b.\n",
    "    \n",
    "    Args:\n",
    "        mask_a: numpy array of shape (H, W). Binary mask of object A.\n",
    "        mask_b: numpy array of shape (H, W). Binary mask of object B.\n",
    "\n",
    "    Returns:\n",
    "        bool. True if there is overlap, False otherwise.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check the inputs are binary masks\n",
    "    assert mask_a.shape == mask_b.shape, \"Both masks should have the same shape.\"\n",
    "    assert np.logical_or(mask_a == 0, mask_a == 1).all(), \"Mask A should be a binary mask.\"\n",
    "    assert np.logical_or(mask_b == 0, mask_b == 1).all(), \"Mask B should be a binary mask.\"\n",
    "\n",
    "    # Find the lowest true point in mask A \n",
    "    y_coords, _ = np.nonzero(mask_a)\n",
    "    lowest_point = int(np.max(y_coords) * 0.9 )#(huamn feet point)\n",
    "\n",
    "    mask_a_copy = mask_a.copy()\n",
    "    # Slice mask A from the lowest point to the top\n",
    "    mask_a_copy[:lowest_point, :] = 0\n",
    "\n",
    "    # Check for overlap\n",
    "    overlap = np.logical_and(mask_a_copy, mask_b)\n",
    "\n",
    "    return np.any(overlap), lowest_point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_overlap(mask_a: np.ndarray, mask_b: np.ndarray):\n",
    "    \"\"\"\n",
    "    Compute the percentage of mutual coverage between mask_a and mask_b.\n",
    "    \n",
    "    Args:\n",
    "        mask_a: numpy array of shape (H, W). Binary mask of object A.\n",
    "        mask_b: numpy array of shape (H, W). Binary mask of object B.\n",
    "\n",
    "    Returns:\n",
    "        float. The percentage of mutual coverage.\n",
    "    \"\"\"\n",
    "    # Check the inputs are binary masks\n",
    "    assert mask_a.shape == mask_b.shape, \"Both masks should have the same shape.\"\n",
    "    assert np.logical_or(mask_a == 0, mask_a == 1).all(), \"Mask A should be a binary mask.\"\n",
    "    assert np.logical_or(mask_b == 0, mask_b == 1).all(), \"Mask B should be a binary mask.\"\n",
    "\n",
    "    # Compute the intersection between the two masks\n",
    "    intersection = np.logical_and(mask_a, mask_b)\n",
    "    \n",
    "    # Compute the union of the two masks\n",
    "    union = np.logical_or(mask_a, mask_b)\n",
    "\n",
    "    # Calculate the mutual coverage percentage\n",
    "    overlap_percentage = np.sum(intersection) / np.sum(union)\n",
    "\n",
    "    return overlap_percentage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surface Utility Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location(bbox:np.ndarray, img_shape:np.ndarray):\n",
    "    img_height, img_width = img_shape[:2]\n",
    "    x_center = (bbox[0] + bbox[2]) / 2\n",
    "    y_center = (bbox[1] + bbox[3]) / 2\n",
    "\n",
    "    if x_center < img_width / 3:\n",
    "        x_pos = \"left\"\n",
    "    elif x_center < 2 * img_width / 3:\n",
    "        x_pos = \"middle\"\n",
    "    else:\n",
    "        x_pos = \"right\"\n",
    "\n",
    "    if y_center < img_height / 2:\n",
    "        y_pos = \"up\"\n",
    "    else:\n",
    "        y_pos = \"down\"\n",
    "\n",
    "    return f\"{x_pos}_{y_pos}\"\n",
    "\n",
    "def `get_surface_info(obj_dict:Counter , f):\n",
    "    \n",
    "    for key, obj_info in obj_dict.items():\n",
    "        object_type = obj_info.object_type\n",
    "        id = obj_info.id\n",
    "        bbox = obj_info.box\n",
    "        h, w = obj_info.mask.shape[-2:]\n",
    "        location = get_location(bbox, (h, w)) \n",
    "        if DEBUG:\n",
    "            print(f\"{object_type} {id} is at {location}\")\n",
    "        f.write(f\"{object_type} {id} is at {location}\\n\")\n",
    "        if obj_info.object_type == \"person\":\n",
    "            f.write(f\"The [distance,angle] from {object_type} {id} to our dashcam is: [{obj_info.distance},{obj_info.angle}]\\n\")\n",
    "            if DEBUG:\n",
    "                print(f\"The [distance,angle] from {object_type} {id} to our dashcam is: [{obj_info.distance},{obj_info.angle}]\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the estimated angle of each person to the dashcam\n",
    "def estimate_angle(image, person:LocationInfo, fov_horizontal = 170):\n",
    "    \n",
    "    # Step 1: Filter out detections that are not pedestrians\n",
    "    if person.object_type!= 'person':\n",
    "        return None\n",
    "    \n",
    "    # Step 2: Estimate distance\n",
    "    box = person.box\n",
    "    bottom_center = (box[0]+box[2])/2, box[3] # feet \n",
    "    distance = person.distance\n",
    "    # Step 3: Estimate angle\n",
    "    image_center_y = image.shape[1] / 2\n",
    "    pedestrian_center = bottom_center[0]\n",
    "    relative_position = pedestrian_center - image_center_y\n",
    "    # Why?\n",
    "    angle = np.arctan(relative_position / distance * np.tan(fov_horizontal / 2))\n",
    "    \n",
    "    return np.degrees(angle)\n",
    "# Get the estimated angle of each person to the dashcam\n",
    "def estimate_angle(image, person:LocationInfo, fov_horizontal = 170):\n",
    "    \n",
    "    # Step 1: Filter out detections that are not pedestrians\n",
    "    if person.object_type!= 'person':\n",
    "        return None\n",
    "    \n",
    "    # Step 2: Estimate distance\n",
    "    box = person.box\n",
    "    bottom_center = (box[0]+box[2])/2, box[3] # feet \n",
    "    \n",
    "    distance = person.distance\n",
    "    # If the distance is a descriptive string, we need to convert it into a numerical representation\n",
    "    if isinstance(distance, str):\n",
    "        distance_mapping = {\"very close\": 1, \"close\": 2, \"median\": 3, \"far\": 4, \"very far\": 5}\n",
    "        if distance in distance_mapping:\n",
    "            distance = distance_mapping[distance]\n",
    "        else:\n",
    "            print(f\"Invalid distance description: {distance}\")\n",
    "            return None\n",
    "    elif not isinstance(distance, (int, float)):\n",
    "        print(f\"Invalid distance type: {type(distance)}\")\n",
    "        return None\n",
    "    \n",
    "    # Step 3: Estimate angle\n",
    "    image_center_y = image.shape[1] / 2\n",
    "    pedestrian_center = bottom_center[0]\n",
    "    relative_position = pedestrian_center - image_center_y\n",
    "\n",
    "    angle = np.arctan(relative_position / distance * np.tan(np.radians(fov_horizontal) / 2))\n",
    "    \n",
    "    return np.degrees(angle)\n",
    "\n",
    "def describe_angle(angle):\n",
    "    \"\"\"Describe the angle in simple terms.\"\"\"\n",
    "    if angle == None:\n",
    "        return \"unknown\"\n",
    "    # Handle the straight-ahead case\n",
    "    if -10 <= angle <= 10:\n",
    "        return \"straight ahead\"\n",
    "\n",
    "    # Handle the right side\n",
    "    if 10 < angle <= 45:\n",
    "        return \"slightly to the right\"\n",
    "    elif 45 < angle <= 135:\n",
    "        return \"to the right\"\n",
    "    elif angle > 135:\n",
    "        return \"far to the right\"\n",
    "\n",
    "    # Handle the left side\n",
    "    if -45 >= angle > -10:\n",
    "        return \"slightly to the left\"\n",
    "    elif -135 >= angle > -45:\n",
    "        return \"to the left\"\n",
    "    elif angle < -135:\n",
    "        return \"far to the left\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_print(obj_dict,image):\n",
    "    for name, person in obj_dict.items():\n",
    "        print(name)\n",
    "        print(person.box)\n",
    "        print(person.distance)\n",
    "        person.angle = estimate_angle(image,person)\n",
    "\n",
    "        print(f\"angle is {person.angle},it is {describe_angle(person.angle)}\")\n",
    "        print(\"\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_txt(image_path, output_path, p_surface_overlaps, counts, labels, p_labels,obj_dict):\n",
    "    '''\n",
    "    str image_path: the relative path to input image\n",
    "    str output_path: \"DINOmasked/video_0018/man.png\"\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    output_dir = Path(output_path).parent\n",
    "    img_name = image_path[-8:-4]\n",
    "    txt_name = \"Info_Video_\"+ str(output_dir)[-4:] +\".txt\"\n",
    "    txt_path = os.path.join(output_dir, txt_name) \n",
    "\n",
    "    if DEBUG:\n",
    "        print(\"output_dir: \", output_dir)\n",
    "        print(\"image_name: \", img_name)\n",
    "        print(\"txt_path: \", txt_path)\n",
    "    # Check if file already exists\n",
    "    # if DEBUG:\n",
    "    #     if os.path.exists(txt_path):\n",
    "    #         # Read in existing data\n",
    "    #         with open(txt_path, 'r') as f:\n",
    "    #             existing_data = f.read()\n",
    "\n",
    "    #         # If the info of the current image has already been recorded, return without appending\n",
    "    #         if f\"INFO of {img_name}:\\n\" in existing_data:\n",
    "    #             print(f\"ERROR: the info of{img_name} has been generated\")\n",
    "    #             return\n",
    "    with open(txt_path, 'a') as f: # 'a' option is for appending to the file if it exists\n",
    "        f.write(f\"INFO of {img_name}:\\n\")\n",
    "\n",
    "        get_surface_info(obj_dict,f)\n",
    "        \n",
    "        for person, surfaces in p_surface_overlaps:\n",
    "            if surfaces:\n",
    "                surface_str = ', '.join([f\"{surface.object_type} {surface.id}\" for surface in surfaces])\n",
    "                f.write(f\"Person {person.id} is on the {surface_str},his/her bbox is {person.box}\\n\")\n",
    "            else:\n",
    "                f.write(f\"Person {person.id} is not on any detected surface\\n\")\n",
    "                \n",
    "        f.write(f\"number of Surface mask, Road&sidewalk, People 's mask, actural people: {counts}\\n\")\n",
    "        f.write(f\"Labels: [{', '.join(labels)}]\\n\")\n",
    "        f.write(f\"Person Labels: [{', '.join(p_labels)}]\\n\\n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompting SAM with Region of Interest\n",
    "def segment_ROI(sam_predictor: SamPredictor, image: np.ndarray, boxes: np.ndarray):\n",
    "\n",
    "    sam_predictor.set_image(image)\n",
    "    result_masks = []\n",
    "    for box in boxes:\n",
    "        masks_np, iou_predictions, _ = sam_predictor.predict(\n",
    "        point_coords=None,\n",
    "        point_labels=None,\n",
    "        box=box,\n",
    "        multimask_output=True,\n",
    "        )\n",
    "        #TODO Remove the following line to get all the person masks\n",
    "        # index = np.argmax(scores_np) \n",
    "        # Add all masks to the result, not just the one with the highest score\n",
    "        # Filter out masks with IoU scores below the threshold\n",
    "        for mask, score in zip(masks_np, iou_predictions):\n",
    "            if score >= IOU_THRESHOLD:\n",
    "                result_masks.append(mask)\n",
    "\n",
    "    return np.array(result_masks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_road(image_path,output_path):\n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Image at path {image_path} could not be loaded. Skipping.\")\n",
    "            return None\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process image at {image_path}. Error: {e}\")\n",
    "        return None\n",
    "    \n",
    "    ROAD_SIDEWALK = ['road', 'sidewalk'] \n",
    "    P_CLASS     = ['person'] #,'bike']\n",
    "    # the person label lower gDINO's performance\n",
    "    # so I split them\n",
    "\n",
    "    # detect road and sidewalk\n",
    "    detections = grounding_dino_model.predict_with_classes(\n",
    "        image=image,\n",
    "        classes = ROAD_SIDEWALK,\n",
    "        box_threshold= BOX_TRESHOLD,\n",
    "        text_threshold=TEXT_TRESHOLD\n",
    "    )\n",
    "    detections = nms_processing(detections)\n",
    "    # detect person \n",
    "    p_detections = grounding_dino_model.predict_with_classes(\n",
    "        image = image,\n",
    "        classes = P_CLASS , \n",
    "        box_threshold= BOX_TRESHOLD,\n",
    "        text_threshold=PED_TRESHOLD \n",
    "    )\n",
    "    p_detections = nms_processing(p_detections)\n",
    "\n",
    "    box_annotator = sv.BoxAnnotator()\n",
    "    person_annotator = sv.BoxAnnotator()\n",
    "\n",
    "    labels = [\n",
    "        f\"{ROAD_SIDEWALK[class_id]} {i} {confidence:0.2f}\" \n",
    "        for i, (_, _, confidence, class_id, _) in enumerate(detections)]\n",
    "\n",
    "    P_labels = [\n",
    "        f\"{P_CLASS[class_id]} {i} {confidence:0.2f}\" \n",
    "        for i, (_, _, confidence, class_id, _) in enumerate(p_detections)]\n",
    "\n",
    "    DINO_boxes = np.array(detections.xyxy)\n",
    "    P_boxes    = np.array(p_detections.xyxy)\n",
    "    \n",
    "    annotated_frame = box_annotator.annotate(scene=image.copy(), detections=detections ,labels=labels)\n",
    "    if DEBUG:\n",
    "        sv.plot_image(annotated_frame, (16, 16))\n",
    "    person_annotation = person_annotator.annotate(scene=annotated_frame,detections= p_detections,labels= P_labels)\n",
    "    if DEBUG:\n",
    "        sv.plot_image(person_annotation, (16, 16))\n",
    "        \n",
    "    cv2.imwrite(output_path, annotated_frame)\n",
    "    \n",
    "    SAM_masks = segment_ROI(sam_predictor,image,DINO_boxes)\n",
    "    P_masks = segment_ROI(sam_predictor,image,DINO_boxes)\n",
    "\n",
    "    # Create a list of LocationInfo objects for each detected object\n",
    "    obj_dict = Counter()\n",
    "    \n",
    "    for i, (box, label, mask) in enumerate(zip(DINO_boxes, labels, SAM_masks)):\n",
    "        object_type, id, confidence   = label.split(' ')\n",
    "        index = object_type +id\n",
    "        obj_dict[index] =  (LocationInfo(object_type, int(id), box, mask,confidence)) \n",
    "\n",
    "    for i, (box, label, mask) in enumerate(zip(P_boxes, P_labels, P_masks)):\n",
    "        object_type, id, confidence = label.split(' ')\n",
    "        index = object_type+id\n",
    "        obj_dict[index] = (LocationInfo(object_type, int(id), box, mask,confidence)) \n",
    "\n",
    "    depth_map = predict_depth(image_path,output_path)\n",
    "    \n",
    "    # Analyze where each person is standing\n",
    "    p_surface_overlaps = []\n",
    "    \n",
    "    for name, person in obj_dict.items():\n",
    "        if person.object_type != \"person\":\n",
    "            continue # We only want to analyze persons\n",
    "        person.distance = get_distance_category(depth_map,person.mask)\n",
    "        person.angle   = estimate_angle(image,person)\n",
    "        \n",
    "        overlaps = []\n",
    "        for name, surface in obj_dict.items():\n",
    "            # We only want to analyze surfaces (road or sidewalk)\n",
    "            if surface.object_type not in ROAD_SIDEWALK: \n",
    "                continue\n",
    "\n",
    "            # Check if the person and the surface overlap\n",
    "            overlap, _ = is_overlap(person.mask, surface.mask)\n",
    "            if overlap:\n",
    "                overlaps.append(surface)\n",
    "\n",
    "        p_surface_overlaps.append((person, overlaps))\n",
    "\n",
    "\n",
    "    if DEBUG:\n",
    "        # Print out the analysis results\n",
    "        for person, surfaces in p_surface_overlaps:\n",
    "            if surfaces:\n",
    "                surface_str = ', '.join([f\"{surface.object_type} {surface.id}\" for surface in surfaces])\n",
    "                print(f\"Person {person.id} is on the {surface_str}\")\n",
    "            else:\n",
    "                print(f\"Person {person.id} is not on any detected surface\")\n",
    "\n",
    "    (i, j, k, d) = display_mask(SAM_masks,P_masks,P_boxes,DINO_boxes,person_annotation,output_path)\n",
    "    \n",
    "\n",
    "    write_to_txt(image_path, output_path, p_surface_overlaps, (i, j, k, d), labels, P_labels,obj_dict)\n",
    "\n",
    "    plt.close()\n",
    "    \n",
    "    # return DINO_boxes,labels,P_labels,SAM_masks,P_masks\n",
    "    return obj_dict\n",
    "\n",
    "# obj_dict,image = detect_road(\"input/scene_2.png\",output_path=\"DINO_masked/scene_2.png\")\n",
    "# DINO_boxes,labels,P_labels,SAM_masks,P_masks = detect_road(\"input/video_0031/image_0005.png\",output_path=\"DINOmasked/man.png\")\n",
    "# DINO_boxes,labels,P_labels,SAM_masks,P_masks = detect_road(\"JAAD_seg_by_sec/video_0268/image_0001.png\",output_path=\"DINOmasked/video_0268/image_0001.png\")\n",
    "# DINO_boxes,labels,P_labels,SAM_masks,P_masks = detect_road(\"JAAD_seg_by_sec/video_0268/image_0003.png\",output_path=\"DINOmasked/video_0268/image_0003.png\")\n",
    "# obj_dict,labels,p_labels =  detect_road(\"JAAD_seg_by_sec/video_0060/image_0005.png\",output_path=\"SSS.png\" )# \"DINOmasked/video_0060/image_0005.png\")\n",
    "# obj_dict =  detect_road(\"input/S0710/image_0005.png\",output_path=\"SSS.png\" )# \"DINOmasked/video_0060/image_0005.png\")\n",
    "\n",
    "# obj_print(obj_dict,image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File IO logic\n",
    "the following code demonstrate how is the IO logic organized\n",
    "\n",
    "For the sake of fast file inquiry, I used library: Path() and os\n",
    "\n",
    "Feel free to modify this part if you need, just in case the content is too big, which may crash the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DINOmasked/video_0018\n",
      "DINOmasked/video_0018/Info_Video_0018.txt\n"
     ]
    }
   ],
   "source": [
    "image_path = \"input/video_0268/image_0001.png\"\n",
    "output_path = \"DINOmasked/video_0018/man.png\"\n",
    "\n",
    "output_dir = Path(output_path).parent\n",
    "\n",
    "print(output_dir)\n",
    "img_name = image_path[-8:-4]\n",
    "txt_name = \"Info_Video_\"+ str(output_dir)[-4:] +\".txt\"\n",
    "txt_path = os.path.join(output_dir, txt_name) \n",
    "print(txt_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOP RUNNING THE MAIN PROGRAM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Start =====\n",
      "Already scanned DINOmasked/HZ3/video_0072/image_0001.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0072/image_0002.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0072/image_0003.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0072/image_0004.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0072/image_0005.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0072/image_0006.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0072/image_0007.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0072/image_0008.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0072/image_0009.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0072/image_0010.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0072/image_0011.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0072/image_0012.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0072/image_0013.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0072/image_0014.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0072/image_0015.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0072/image_0016.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0072/image_0017.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0072/image_0018.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0072/image_0019.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0072/image_0020.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0072/image_0021.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0073/image_0001.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0073/image_0002.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0073/image_0003.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0073/image_0004.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0073/image_0005.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0073/image_0006.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0073/image_0007.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0073/image_0008.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0073/image_0009.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0073/image_0010.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0073/image_0011.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0073/image_0012.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0001.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0002.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0003.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0004.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0005.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0006.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0007.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0008.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0009.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0010.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0011.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0012.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0013.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0014.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0015.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0016.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0017.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0018.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0019.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0020.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0021.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0022.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0023.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0024.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0025.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0026.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0027.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0028.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0029.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0074/image_0030.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0075/image_0001.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0075/image_0002.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0075/image_0003.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0075/image_0004.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0075/image_0005.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0075/image_0006.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0075/image_0007.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0075/image_0008.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0075/image_0009.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0075/image_0010.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0075/image_0011.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0075/image_0012.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0075/image_0013.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0075/image_0014.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0075/image_0015.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0075/image_0016.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0075/image_0017.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0075/image_0018.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0075/image_0019.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0075/image_0020.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0075/image_0021.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0141/image_0001.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0141/image_0002.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0141/image_0003.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0141/image_0004.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0141/image_0005.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0141/image_0006.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0141/image_0007.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0141/image_0008.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0141/image_0009.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0141/image_0010.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0141/image_0011.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0141/image_0012.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0141/image_0013.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0141/image_0014.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0141/image_0015.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0001.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0002.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0003.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0004.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0005.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0006.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0007.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0008.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0009.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0010.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0011.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0012.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0013.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0014.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0015.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0016.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0017.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0018.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0019.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0020.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0021.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0022.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0023.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0024.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0025.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0026.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0027.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0028.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0029.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0142/image_0030.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0001.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0002.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0003.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0004.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0005.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0006.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0007.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0008.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0009.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0010.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0011.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0012.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0013.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0014.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0015.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0016.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0017.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0018.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0019.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0020.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0021.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0022.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0023.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0024.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0025.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0026.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0027.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0028.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0029.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0143/image_0030.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0144/image_0001.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0144/image_0002.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0144/image_0003.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0144/image_0004.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0144/image_0005.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0144/image_0006.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0144/image_0007.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0144/image_0008.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0144/image_0009.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0144/image_0010.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0144/image_0011.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0144/image_0012.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0144/image_0013.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0144/image_0014.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0144/image_0015.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0144/image_0016.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0144/image_0017.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0144/image_0018.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0144/image_0019.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0144/image_0020.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0144/image_0021.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0144/image_0022.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0144/image_0023.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0144/image_0024.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0144/image_0025.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0144/image_0026.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0144/image_0027.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0001.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0002.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0003.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0004.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0005.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0006.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0007.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0008.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0009.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0010.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0011.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0012.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0013.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0014.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0015.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0016.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0017.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0018.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0019.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0020.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0021.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0022.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0023.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0024.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0025.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0026.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0027.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0028.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0029.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0145/image_0030.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0146/image_0001.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0146/image_0002.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0146/image_0003.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0146/image_0004.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0146/image_0005.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0146/image_0006.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0146/image_0007.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0146/image_0008.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0146/image_0009.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0146/image_0010.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0146/image_0011.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0146/image_0012.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0001.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0002.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0003.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0004.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0005.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0006.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0007.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0008.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0009.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0010.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0011.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0012.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0013.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0014.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0015.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0016.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0017.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0018.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0019.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0020.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0021.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0022.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0023.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0024.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0025.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0026.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0027.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0028.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0029.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0030.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0031.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0032.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0033.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0034.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0035.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0147/image_0036.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0191/image_0001.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0191/image_0002.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0191/image_0003.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0191/image_0004.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0191/image_0005.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0191/image_0006.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0191/image_0007.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0191/image_0008.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0191/image_0009.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0191/image_0010.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0191/image_0011.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0191/image_0012.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0191/image_0013.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0191/image_0014.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0191/image_0015.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0192/image_0001.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0192/image_0002.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0192/image_0003.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0192/image_0004.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0192/image_0005.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0192/image_0006.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0192/image_0007.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0192/image_0008.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0192/image_0009.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0192/image_0010.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0192/image_0011.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0192/image_0012.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0193/image_0001.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0193/image_0002.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0193/image_0003.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0193/image_0004.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0193/image_0005.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0193/image_0006.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0193/image_0007.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0193/image_0008.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0193/image_0009.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0193/image_0010.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0193/image_0011.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0193/image_0012.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0193/image_0013.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0193/image_0014.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0193/image_0015.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0193/image_0016.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0193/image_0017.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0193/image_0018.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0193/image_0019.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0193/image_0020.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0193/image_0021.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0193/image_0022.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0193/image_0023.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0193/image_0024.png, next one\n",
      "Processing:  1\n",
      "Image path: image_0001.png\n",
      "Detected: input/HZ3_output/video_0194/image_0001.png\n",
      "Processing:  2\n",
      "Image path: image_0002.png\n",
      "Detected: input/HZ3_output/video_0194/image_0002.png\n",
      "Processing:  3\n",
      "Image path: image_0003.png\n",
      "Detected: input/HZ3_output/video_0194/image_0003.png\n",
      "Processing:  4\n",
      "Image path: image_0004.png\n",
      "Detected: input/HZ3_output/video_0194/image_0004.png\n",
      "Processing:  5\n",
      "Image path: image_0005.png\n",
      "Detected: input/HZ3_output/video_0194/image_0005.png\n",
      "Processing:  6\n",
      "Image path: image_0006.png\n",
      "Detected: input/HZ3_output/video_0194/image_0006.png\n",
      "Processing:  7\n",
      "Image path: image_0007.png\n",
      "Detected: input/HZ3_output/video_0194/image_0007.png\n",
      "Processing:  8\n",
      "Image path: image_0008.png\n",
      "Detected: input/HZ3_output/video_0194/image_0008.png\n",
      "Processing:  9\n",
      "Image path: image_0009.png\n",
      "Detected: input/HZ3_output/video_0194/image_0009.png\n",
      "Processing:  10\n",
      "Image path: image_0010.png\n",
      "Detected: input/HZ3_output/video_0194/image_0010.png\n",
      "Processing:  11\n",
      "Image path: image_0011.png\n",
      "Detected: input/HZ3_output/video_0194/image_0011.png\n",
      "Processing:  12\n",
      "Image path: image_0012.png\n",
      "Detected: input/HZ3_output/video_0194/image_0012.png\n",
      "Processing:  13\n",
      "Image path: image_0013.png\n",
      "Detected: input/HZ3_output/video_0194/image_0013.png\n",
      "Processing:  14\n",
      "Image path: image_0014.png\n",
      "Detected: input/HZ3_output/video_0194/image_0014.png\n",
      "Processing:  15\n",
      "Image path: image_0015.png\n",
      "Detected: input/HZ3_output/video_0194/image_0015.png\n",
      "Processing:  16\n",
      "Image path: image_0016.png\n",
      "Detected: input/HZ3_output/video_0194/image_0016.png\n",
      "Processing:  17\n",
      "Image path: image_0017.png\n",
      "Detected: input/HZ3_output/video_0194/image_0017.png\n",
      "Processing:  18\n",
      "Image path: image_0018.png\n",
      "Detected: input/HZ3_output/video_0194/image_0018.png\n",
      "Processing:  19\n",
      "Image path: image_0019.png\n",
      "Detected: input/HZ3_output/video_0194/image_0019.png\n",
      "Processing:  20\n",
      "Image path: image_0020.png\n",
      "Detected: input/HZ3_output/video_0194/image_0020.png\n",
      "Processing:  21\n",
      "Image path: image_0021.png\n",
      "Detected: input/HZ3_output/video_0194/image_0021.png\n",
      "Processing:  22\n",
      "Image path: image_0022.png\n",
      "Detected: input/HZ3_output/video_0194/image_0022.png\n",
      "Processing:  23\n",
      "Image path: image_0023.png\n",
      "Detected: input/HZ3_output/video_0194/image_0023.png\n",
      "Processing:  24\n",
      "Image path: image_0024.png\n",
      "Detected: input/HZ3_output/video_0194/image_0024.png\n",
      "Processing:  25\n",
      "Image path: image_0025.png\n",
      "Detected: input/HZ3_output/video_0194/image_0025.png\n",
      "Processing:  26\n",
      "Image path: image_0026.png\n",
      "Detected: input/HZ3_output/video_0194/image_0026.png\n",
      "Processing:  27\n",
      "Image path: image_0027.png\n",
      "Detected: input/HZ3_output/video_0194/image_0027.png\n",
      "Processing:  28\n",
      "Image path: image_0028.png\n",
      "Detected: input/HZ3_output/video_0194/image_0028.png\n",
      "Processing:  29\n",
      "Image path: image_0029.png\n",
      "Detected: input/HZ3_output/video_0194/image_0029.png\n",
      "Processing:  30\n",
      "Image path: image_0030.png\n",
      "Detected: input/HZ3_output/video_0194/image_0030.png\n",
      "Processing:  31\n",
      "Image path: image_0031.png\n",
      "Detected: input/HZ3_output/video_0194/image_0031.png\n",
      "Processing:  32\n",
      "Image path: image_0032.png\n",
      "Detected: input/HZ3_output/video_0194/image_0032.png\n",
      "Processing:  33\n",
      "Image path: image_0033.png\n",
      "Detected: input/HZ3_output/video_0194/image_0033.png\n",
      "Processing:  34\n",
      "Image path: image_0034.png\n",
      "Detected: input/HZ3_output/video_0194/image_0034.png\n",
      "Processing:  35\n",
      "Image path: image_0035.png\n",
      "Detected: input/HZ3_output/video_0194/image_0035.png\n",
      "Processing:  36\n",
      "Image path: image_0036.png\n",
      "Detected: input/HZ3_output/video_0194/image_0036.png\n",
      "Processing:  37\n",
      "Image path: image_0037.png\n",
      "Detected: input/HZ3_output/video_0194/image_0037.png\n",
      "Processing:  38\n",
      "Image path: image_0038.png\n",
      "Detected: input/HZ3_output/video_0194/image_0038.png\n",
      "Processing:  39\n",
      "Image path: image_0039.png\n",
      "Detected: input/HZ3_output/video_0194/image_0039.png\n",
      "Processing:  40\n",
      "Image path: image_0040.png\n",
      "Detected: input/HZ3_output/video_0194/image_0040.png\n",
      "Processing:  41\n",
      "Image path: image_0041.png\n",
      "Detected: input/HZ3_output/video_0194/image_0041.png\n",
      "Processing:  42\n",
      "Image path: image_0042.png\n",
      "Detected: input/HZ3_output/video_0194/image_0042.png\n",
      "Processing:  43\n",
      "Image path: image_0043.png\n",
      "Detected: input/HZ3_output/video_0194/image_0043.png\n",
      "Processing:  44\n",
      "Image path: image_0044.png\n",
      "Detected: input/HZ3_output/video_0194/image_0044.png\n",
      "Processing:  45\n",
      "Image path: image_0045.png\n",
      "Detected: input/HZ3_output/video_0194/image_0045.png\n",
      "Processing:  46\n",
      "Image path: image_0046.png\n",
      "Detected: input/HZ3_output/video_0194/image_0046.png\n",
      "Processing:  47\n",
      "Image path: image_0047.png\n",
      "Detected: input/HZ3_output/video_0194/image_0047.png\n",
      "Processing:  48\n",
      "Image path: image_0048.png\n",
      "Detected: input/HZ3_output/video_0194/image_0048.png\n",
      "Processing:  49\n",
      "Image path: image_0049.png\n",
      "Detected: input/HZ3_output/video_0194/image_0049.png\n",
      "Processing:  50\n",
      "Image path: image_0050.png\n",
      "Detected: input/HZ3_output/video_0194/image_0050.png\n",
      "Processing:  51\n",
      "Image path: image_0051.png\n",
      "Detected: input/HZ3_output/video_0194/image_0051.png\n",
      "Processing:  52\n",
      "Image path: image_0052.png\n",
      "Detected: input/HZ3_output/video_0194/image_0052.png\n",
      "Processing:  53\n",
      "Image path: image_0053.png\n",
      "Detected: input/HZ3_output/video_0194/image_0053.png\n",
      "Processing:  54\n",
      "Image path: image_0054.png\n",
      "Detected: input/HZ3_output/video_0194/image_0054.png\n",
      "Already scanned DINOmasked/HZ3/video_0195/image_0001.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0195/image_0002.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0195/image_0003.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0195/image_0004.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0195/image_0005.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0195/image_0006.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0195/image_0007.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0195/image_0008.png, next one\n",
      "Already scanned DINOmasked/HZ3/video_0195/image_0009.png, next one\n",
      "===== END =====\n"
     ]
    }
   ],
   "source": [
    "input_dir = Path(\"input/HZ3_output/\") # contain many folders  JAAD_seg_by_sec\n",
    "output_dir = Path('DINOmasked/HZ3')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"===== Start =====\")\n",
    "i = 1\n",
    "# Use rglob to recursively find all image files\n",
    "for image_path in input_dir.rglob('*'):\n",
    "    if is_image_file(str(image_path)):\n",
    "        relative_path = image_path.relative_to(input_dir)\n",
    "\n",
    "        output_path = output_dir / relative_path\n",
    "        output_path.parent.mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "        if output_path.exists():\n",
    "            print(f\"Already scanned {output_path}, next one\")\n",
    "            continue\n",
    "        else:\n",
    "            print(\"Processing: \", i)\n",
    "            i += 1\n",
    "            print(f\"Image path: {os.path.basename(str(image_path))}\")\n",
    "\n",
    "            result = detect_road(str(image_path),str(output_path))\n",
    "\n",
    "            if result is not None:\n",
    "                print(f\"Detected: {image_path}\") \n",
    "            else: \n",
    "                print( \"failed to detect result\")\n",
    "\n",
    "print(\"===== END =====\")\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image path is input/man.png\n",
      "output_path path is DINOmasked/HZ3/D_man.png\n",
      "image path is input/man_black.png\n",
      "output_path path is DINOmasked/HZ3/D_man_black.png\n",
      "image path is input/scene_2.png\n",
      "output_path path is DINOmasked/HZ3/D_scene_2.png\n",
      "image path is input/scene_2_black.png\n",
      "output_path path is DINOmasked/HZ3/D_scene_2_black.png\n",
      "image path is input/S0710/image_0003.png\n",
      "output_path path is DINOmasked/HZ3/D_image_0003.png\n",
      "image path is input/S0710/image_0001.png\n",
      "output_path path is DINOmasked/HZ3/D_image_0001.png\n",
      "image path is input/S0710/image_0002.png\n",
      "output_path path is DINOmasked/HZ3/D_image_0002.png\n",
      "image path is input/S0710/image_0006.png\n",
      "output_path path is DINOmasked/HZ3/D_image_0006.png\n",
      "image path is input/S0710/image_0004.png\n",
      "output_path path is DINOmasked/HZ3/D_image_0004.png\n",
      "image path is input/S0710/image_0005.png\n",
      "output_path path is DINOmasked/HZ3/D_image_0005.png\n",
      "image path is input/S0710/image_0008.png\n",
      "output_path path is DINOmasked/HZ3/D_image_0008.png\n",
      "image path is input/S0710/image_0007.png\n",
      "output_path path is DINOmasked/HZ3/D_image_0007.png\n",
      "image path is input/S0710/image_0009.png\n",
      "output_path path is DINOmasked/HZ3/D_image_0009.png\n",
      "image path is input/S0710/image_0011.png\n",
      "output_path path is DINOmasked/HZ3/D_image_0011.png\n",
      "image path is input/S0710/image_0012.png\n",
      "output_path path is DINOmasked/HZ3/D_image_0012.png\n",
      "image path is input/S0710/image_0010.png\n",
      "output_path path is DINOmasked/HZ3/D_image_0010.png\n",
      "image path is input/S0710/image_0014.png\n",
      "output_path path is DINOmasked/HZ3/D_image_0014.png\n",
      "image path is input/S0710/image_0013.png\n",
      "output_path path is DINOmasked/HZ3/D_image_0013.png\n",
      "image path is input/S0710/image_0015.png\n",
      "output_path path is DINOmasked/HZ3/D_image_0015.png\n",
      "image path is input/S0710/image_0017.png\n",
      "output_path path is DINOmasked/HZ3/D_image_0017.png\n",
      "image path is input/S0710/image_0016.png\n",
      "output_path path is DINOmasked/HZ3/D_image_0016.png\n",
      "image path is input/S0710/image_0018.png\n",
      "output_path path is DINOmasked/HZ3/D_image_0018.png\n",
      "image path is input/S0710/image_0019.png\n",
      "output_path path is DINOmasked/HZ3/D_image_0019.png\n",
      "image path is input/video_0310/image_0001.png\n",
      "output_path path is DINOmasked/HZ3/D_image_0001.png\n",
      "image path is input/video_0310/image_0002.png\n",
      "output_path path is DINOmasked/HZ3/D_image_0002.png\n",
      "image path is input/video_0310/image_0003.png\n",
      "output_path path is DINOmasked/HZ3/D_image_0003.png\n",
      "image path is input/video_0310/image_0004.png\n",
      "output_path path is DINOmasked/HZ3/D_image_0004.png\n",
      "image path is input/video_0310/image_0005.png\n",
      "output_path path is DINOmasked/HZ3/D_image_0005.png\n",
      "image path is input/video_0045/image_0001.png\n",
      "output_path path is DINOmasked/HZ3/D_image_0001.png\n",
      "image path is input/video_0045/image_0002.png\n",
      "output_path path is DINOmasked/HZ3/D_image_0002.png\n",
      "image path is input/video_0045/image_0003.png\n",
      "output_path path is DINOmasked/HZ3/D_image_0003.png\n"
     ]
    }
   ],
   "source": [
    "input_dir  = Path(\"input\")\n",
    "i = 0\n",
    "for image_path in input_dir.rglob('*'):\n",
    "    if i > 30: break\n",
    "    \n",
    "    if is_image_file(str(image_path)):\n",
    "        i += 1\n",
    "\n",
    "        print(\"image path is\" ,image_path)\n",
    "        relative_path = image_path.relative_to(input_dir)\n",
    "\n",
    "        output_filename = 'D_' + relative_path.name\n",
    "        \n",
    "        output_path = Path(os.path.join( output_dir , output_filename))\n",
    "        print(\"output_path path is\" ,output_path)\n",
    "        output_path.parent.mkdir(parents=True,exist_ok=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
